{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extract Verb in PIQA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import spacy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Open PIQA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal</th>\n",
       "      <th>sol1</th>\n",
       "      <th>sol2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When boiling butter, when it's ready, you can</td>\n",
       "      <td>Pour it onto a plate</td>\n",
       "      <td>Pour it into a jar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To permanently attach metal legs to a chair, y...</td>\n",
       "      <td>Weld the metal together to get it to stay firm...</td>\n",
       "      <td>Nail the metal together to get it to stay firm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how do you indent something?</td>\n",
       "      <td>leave a space before starting the writing</td>\n",
       "      <td>press the spacebar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how do you shake something?</td>\n",
       "      <td>move it up and down and side to side quickly.</td>\n",
       "      <td>stir it very quickly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clean tires</td>\n",
       "      <td>Pour water, cape off caked on dirt. Use  speed...</td>\n",
       "      <td>Pour water, scrape off caked on dirt. Use a st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                goal  \\\n",
       "0      When boiling butter, when it's ready, you can   \n",
       "1  To permanently attach metal legs to a chair, y...   \n",
       "2                       how do you indent something?   \n",
       "3                        how do you shake something?   \n",
       "4                                        Clean tires   \n",
       "\n",
       "                                                sol1  \\\n",
       "0                               Pour it onto a plate   \n",
       "1  Weld the metal together to get it to stay firm...   \n",
       "2          leave a space before starting the writing   \n",
       "3      move it up and down and side to side quickly.   \n",
       "4  Pour water, cape off caked on dirt. Use  speed...   \n",
       "\n",
       "                                                sol2  \n",
       "0                                 Pour it into a jar  \n",
       "1  Nail the metal together to get it to stay firm...  \n",
       "2                                 press the spacebar  \n",
       "3                              stir it very quickly.  \n",
       "4  Pour water, scrape off caked on dirt. Use a st...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp = []\n",
    "with open('./PIQA/train.jsonl') as f:\n",
    "    for obj in f:\n",
    "        tmp.append(json.loads(obj))\n",
    "\n",
    "piqa_train = pd.DataFrame(tmp)\n",
    "display(piqa_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal</th>\n",
       "      <th>sol1</th>\n",
       "      <th>sol2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I ready a guinea pig cage for it's new ...</td>\n",
       "      <td>Provide the guinea pig with a cage full of a f...</td>\n",
       "      <td>Provide the guinea pig with a cage full of a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dresser</td>\n",
       "      <td>replace drawer with bobby pin</td>\n",
       "      <td>finish, woodgrain with  bobby pin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To fight Ivan Drago in Rocky for sega master s...</td>\n",
       "      <td>Drago isn't in this game because it was releas...</td>\n",
       "      <td>You have to defeat Apollo Creed and Clubber La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Make outdoor pillow.</td>\n",
       "      <td>Blow into tin can and tie with rubber band.</td>\n",
       "      <td>Blow into trash bag and tie with rubber band.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ice box</td>\n",
       "      <td>will turn into a cooler if you add water to it</td>\n",
       "      <td>will turn into a cooler if you add soda to it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                goal  \\\n",
       "0  How do I ready a guinea pig cage for it's new ...   \n",
       "1                                            dresser   \n",
       "2  To fight Ivan Drago in Rocky for sega master s...   \n",
       "3                               Make outdoor pillow.   \n",
       "4                                            ice box   \n",
       "\n",
       "                                                sol1  \\\n",
       "0  Provide the guinea pig with a cage full of a f...   \n",
       "1                     replace drawer with bobby pin    \n",
       "2  Drago isn't in this game because it was releas...   \n",
       "3        Blow into tin can and tie with rubber band.   \n",
       "4     will turn into a cooler if you add water to it   \n",
       "\n",
       "                                                sol2  \n",
       "0  Provide the guinea pig with a cage full of a f...  \n",
       "1                 finish, woodgrain with  bobby pin   \n",
       "2  You have to defeat Apollo Creed and Clubber La...  \n",
       "3      Blow into trash bag and tie with rubber band.  \n",
       "4      will turn into a cooler if you add soda to it  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp = []\n",
    "with open('./PIQA/valid.jsonl') as f:\n",
    "    for obj in f:\n",
    "        tmp.append(json.loads(obj))\n",
    "\n",
    "piqa_valid = pd.DataFrame(tmp)\n",
    "display(piqa_valid.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal</th>\n",
       "      <th>sol1</th>\n",
       "      <th>sol2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how do you puncture a vein?</td>\n",
       "      <td>hit it at the wrong angle and make it bleed.</td>\n",
       "      <td>pop it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hands</td>\n",
       "      <td>is used to put on shoe</td>\n",
       "      <td>is used to put on milk jug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What ingredients do I need to make a shortcrus...</td>\n",
       "      <td>To make pie crust, you will need flour, sugar,...</td>\n",
       "      <td>To make pie crust, you will need flour, sugar,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roast broccoli</td>\n",
       "      <td>Preheat oven to 450 degrees F.    Toss the bro...</td>\n",
       "      <td>Preheat oven to 450 degrees F.    Toss the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To crimp the edges of the patsy crust.</td>\n",
       "      <td>Use a knife to crimp the edges.</td>\n",
       "      <td>Use a fork to crimp the edges</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                goal  \\\n",
       "0                        how do you puncture a vein?   \n",
       "1                                              hands   \n",
       "2  What ingredients do I need to make a shortcrus...   \n",
       "3                                     roast broccoli   \n",
       "4             To crimp the edges of the patsy crust.   \n",
       "\n",
       "                                                sol1  \\\n",
       "0       hit it at the wrong angle and make it bleed.   \n",
       "1                            is used to put on shoe    \n",
       "2  To make pie crust, you will need flour, sugar,...   \n",
       "3  Preheat oven to 450 degrees F.    Toss the bro...   \n",
       "4                    Use a knife to crimp the edges.   \n",
       "\n",
       "                                                sol2  \n",
       "0                                            pop it.  \n",
       "1                        is used to put on milk jug   \n",
       "2  To make pie crust, you will need flour, sugar,...  \n",
       "3  Preheat oven to 450 degrees F.    Toss the bro...  \n",
       "4                      Use a fork to crimp the edges  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp = []\n",
    "with open('./PIQA/tests.jsonl') as f:\n",
    "    for obj in f:\n",
    "        tmp.append(json.loads(obj))\n",
    "\n",
    "piqa_tests = pd.DataFrame(tmp)\n",
    "display(piqa_tests.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Extract PIQA Verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```$ python -m spacy download en_core_web_sm```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```$ python -m spacy download en_core_web_trf```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16113\n"
     ]
    }
   ],
   "source": [
    "piqa_train_length = len(piqa_train)\n",
    "print(piqa_train_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1838\n"
     ]
    }
   ],
   "source": [
    "piqa_valid_length = len(piqa_valid)\n",
    "print(piqa_valid_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3084\n"
     ]
    }
   ],
   "source": [
    "piqa_tests_length = len(piqa_tests)\n",
    "print(piqa_tests_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Extract Verbs by ```en_core_web_sm```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16113/16113 [03:41<00:00, 72.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "piqa_train['verbs'] = None\n",
    "piqa_train_verbs = set()\n",
    "\n",
    "for row in tqdm(piqa_train.itertuples(), total=piqa_train_length):\n",
    "    col1 = nlp(row.goal)\n",
    "    col2 = nlp(row.sol1)\n",
    "    col3 = nlp(row.sol2)\n",
    "    \n",
    "    tmp = set()\n",
    "    tmp.update([token.lemma_ for token in col1 if token.pos_ == 'VERB'])\n",
    "    tmp.update([token.lemma_ for token in col2 if token.pos_ == 'VERB'])\n",
    "    tmp.update([token.lemma_ for token in col3 if token.pos_ == 'VERB'])\n",
    "\n",
    "    piqa_train.at[row.Index, 'verbs'] = tmp\n",
    "    piqa_train_verbs.update(tmp)\n",
    "\n",
    "print(len(piqa_train_verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1838/1838 [00:24<00:00, 75.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "piqa_valid['verbs'] = None\n",
    "piqa_valid_verbs = set()\n",
    "\n",
    "for row in tqdm(piqa_valid.itertuples(), total=piqa_valid_length):\n",
    "    col1 = nlp(row.goal)\n",
    "    col2 = nlp(row.sol1)\n",
    "    col3 = nlp(row.sol2)\n",
    "    \n",
    "    tmp = set()\n",
    "    tmp.update([token.lemma_ for token in col1 if token.pos_ == 'VERB'])\n",
    "    tmp.update([token.lemma_ for token in col2 if token.pos_ == 'VERB'])\n",
    "    tmp.update([token.lemma_ for token in col3 if token.pos_ == 'VERB'])\n",
    "\n",
    "    piqa_valid.at[row.Index, 'verbs'] = tmp\n",
    "    piqa_valid_verbs.update(tmp)\n",
    "\n",
    "print(len(piqa_valid_verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3084/3084 [00:39<00:00, 77.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "piqa_tests['verbs'] = None\n",
    "piqa_tests_verbs = set()\n",
    "\n",
    "for row in tqdm(piqa_tests.itertuples(), total=piqa_tests_length):\n",
    "    col1 = nlp(row.goal)\n",
    "    col2 = nlp(row.sol1)\n",
    "    col3 = nlp(row.sol2)\n",
    "    \n",
    "    tmp = set()\n",
    "    tmp.update([token.lemma_ for token in col1 if token.pos_ == 'VERB'])\n",
    "    tmp.update([token.lemma_ for token in col2 if token.pos_ == 'VERB'])\n",
    "    tmp.update([token.lemma_ for token in col3 if token.pos_ == 'VERB'])\n",
    "\n",
    "    piqa_tests.at[row.Index, 'verbs'] = tmp\n",
    "    piqa_tests_verbs.update(tmp)\n",
    "\n",
    "print(len(piqa_tests_verbs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Save Extracted Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "piqa_train_verbs_df = pd.DataFrame(piqa_train_verbs)\n",
    "piqa_train_verbs_df.to_csv(\"./output/piqa_train_verbs.txt\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "piqa_valid_verbs_df = pd.DataFrame(piqa_valid_verbs)\n",
    "piqa_valid_verbs_df.to_csv(\"./output/piqa_valid_verbs.txt\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "piqa_tests_verbs_df = pd.DataFrame(piqa_tests_verbs)\n",
    "piqa_tests_verbs_df.to_csv(\"./output/piqa_tests_verbs.txt\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3100\n"
     ]
    }
   ],
   "source": [
    "piqa_verbs = set()\n",
    "piqa_verbs.update(piqa_train_verbs)\n",
    "piqa_verbs.update(piqa_valid_verbs)\n",
    "piqa_verbs.update(piqa_tests_verbs)\n",
    "\n",
    "print(len(piqa_verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "piqa_verbs_df = pd.DataFrame(piqa_verbs)\n",
    "piqa_verbs_df.to_csv(\"./output/piqa_verbs.txt\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Collect ATOMIC which including PIQA-Verb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Open ATOMIC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PersonX abandons ___ altogether</td>\n",
       "      <td>oEffect</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PersonX abandons ___ altogether</td>\n",
       "      <td>oEffect</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PersonX abandons ___ altogether</td>\n",
       "      <td>oReact</td>\n",
       "      <td>dejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PersonX abandons ___ altogether</td>\n",
       "      <td>oWant</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PersonX abandons ___ altogether</td>\n",
       "      <td>oWant</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              head relation      tail\n",
       "0  PersonX abandons ___ altogether  oEffect      none\n",
       "1  PersonX abandons ___ altogether  oEffect      none\n",
       "2  PersonX abandons ___ altogether   oReact  dejected\n",
       "3  PersonX abandons ___ altogether    oWant      none\n",
       "4  PersonX abandons ___ altogether    oWant      none"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colnames = ['head', 'relation', 'tail']\n",
    "atomic_train = pd.read_csv('./atomic2020/train.tsv', sep='\\t', names=colnames, header=None)\n",
    "display(atomic_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PersonX 'd better go</td>\n",
       "      <td>oEffect</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PersonX 'd better go</td>\n",
       "      <td>oEffect</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PersonX 'd better go</td>\n",
       "      <td>oReact</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PersonX 'd better go</td>\n",
       "      <td>oReact</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PersonX 'd better go</td>\n",
       "      <td>oWant</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   head relation  tail\n",
       "0  PersonX 'd better go  oEffect  none\n",
       "1  PersonX 'd better go  oEffect  none\n",
       "2  PersonX 'd better go   oReact  none\n",
       "3  PersonX 'd better go   oReact  none\n",
       "4  PersonX 'd better go    oWant  none"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "atomic_dev = pd.read_csv('./atomic2020/dev.tsv', sep='\\t', names=colnames, header=None)\n",
    "display(atomic_dev.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PersonX abuses PersonX's power</td>\n",
       "      <td>oEffect</td>\n",
       "      <td>are told what to do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PersonX abuses PersonX's power</td>\n",
       "      <td>oEffect</td>\n",
       "      <td>given unfair consequences or punishment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PersonX abuses PersonX's power</td>\n",
       "      <td>oEffect</td>\n",
       "      <td>reach out for help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PersonX abuses PersonX's power</td>\n",
       "      <td>oEffect</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PersonX abuses PersonX's power</td>\n",
       "      <td>oReact</td>\n",
       "      <td>humiliated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             head relation  \\\n",
       "0  PersonX abuses PersonX's power  oEffect   \n",
       "1  PersonX abuses PersonX's power  oEffect   \n",
       "2  PersonX abuses PersonX's power  oEffect   \n",
       "3  PersonX abuses PersonX's power  oEffect   \n",
       "4  PersonX abuses PersonX's power   oReact   \n",
       "\n",
       "                                      tail  \n",
       "0                      are told what to do  \n",
       "1  given unfair consequences or punishment  \n",
       "2                       reach out for help  \n",
       "3                                     none  \n",
       "4                               humiliated  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "atomic_test = pd.read_csv('./atomic2020/test.tsv', sep='\\t', names=colnames, header=None)\n",
    "display(atomic_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Load PIQA Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3100\n"
     ]
    }
   ],
   "source": [
    "piqa_verbs = set(line.strip() for line in open('./output/piqa_verbs.txt'))\n",
    "print(len(piqa_verbs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Extract ATOMIC Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076880\n"
     ]
    }
   ],
   "source": [
    "atomic_train_length = len(atomic_train)\n",
    "print(atomic_train_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102024\n"
     ]
    }
   ],
   "source": [
    "atomic_dev_length = len(atomic_dev)\n",
    "print(atomic_dev_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152209\n"
     ]
    }
   ],
   "source": [
    "atomic_test_length = len(atomic_test)\n",
    "print(atomic_test_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>verbs_head</th>\n",
       "      <th>verbs_tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>PersonX affects PersonY's health</td>\n",
       "      <td>oReact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6018</th>\n",
       "      <td>PersonX affects PersonY's health</td>\n",
       "      <td>xReact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>PersonX affects PersonY's life</td>\n",
       "      <td>xReact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17115</th>\n",
       "      <td>PersonX asks PersonY to let</td>\n",
       "      <td>oReact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36675</th>\n",
       "      <td>PersonX binds together the ___</td>\n",
       "      <td>xReact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063998</th>\n",
       "      <td>PersonX uses PersonX's internet</td>\n",
       "      <td>HinderedBy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064418</th>\n",
       "      <td>PersonX hears a knock</td>\n",
       "      <td>HinderedBy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064740</th>\n",
       "      <td>PersonX plays catch</td>\n",
       "      <td>HinderedBy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064868</th>\n",
       "      <td>PersonX shows it to PersonY's parents</td>\n",
       "      <td>HinderedBy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064877</th>\n",
       "      <td>PersonX takes PersonY out to eat</td>\n",
       "      <td>HinderedBy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          head    relation tail verbs_head  \\\n",
       "6000          PersonX affects PersonY's health      oReact  NaN       None   \n",
       "6018          PersonX affects PersonY's health      xReact  NaN       None   \n",
       "6048            PersonX affects PersonY's life      xReact  NaN       None   \n",
       "17115              PersonX asks PersonY to let      oReact  NaN       None   \n",
       "36675           PersonX binds together the ___      xReact  NaN       None   \n",
       "...                                        ...         ...  ...        ...   \n",
       "1063998        PersonX uses PersonX's internet  HinderedBy  NaN       None   \n",
       "1064418                  PersonX hears a knock  HinderedBy  NaN       None   \n",
       "1064740                    PersonX plays catch  HinderedBy  NaN       None   \n",
       "1064868  PersonX shows it to PersonY's parents  HinderedBy  NaN       None   \n",
       "1064877       PersonX takes PersonY out to eat  HinderedBy  NaN       None   \n",
       "\n",
       "        verbs_tail  \n",
       "6000          None  \n",
       "6018          None  \n",
       "6048          None  \n",
       "17115         None  \n",
       "36675         None  \n",
       "...            ...  \n",
       "1063998       None  \n",
       "1064418       None  \n",
       "1064740       None  \n",
       "1064868       None  \n",
       "1064877       None  \n",
       "\n",
       "[145 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check if tail is float\n",
    "display(atomic_train[atomic_train['tail'].apply(lambda x: isinstance(x, float))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8760/1076880 [00:46<1:34:11, 189.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/woojinkim/Codes/commonsense-reasoning/atomic-extract.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/woojinkim/Codes/commonsense-reasoning/atomic-extract.ipynb#X64sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/woojinkim/Codes/commonsense-reasoning/atomic-extract.ipynb#X64sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m col1 \u001b[39m=\u001b[39m nlp(row\u001b[39m.\u001b[39mhead)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/woojinkim/Codes/commonsense-reasoning/atomic-extract.ipynb#X64sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m col2 \u001b[39m=\u001b[39m nlp(row\u001b[39m.\u001b[39;49mtail)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/woojinkim/Codes/commonsense-reasoning/atomic-extract.ipynb#X64sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m tmp1 \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m([token\u001b[39m.\u001b[39mlemma_ \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m col1 \u001b[39mif\u001b[39;00m token\u001b[39m.\u001b[39mpos_ \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mVERB\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/woojinkim/Codes/commonsense-reasoning/atomic-extract.ipynb#X64sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m tmp2 \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m([token\u001b[39m.\u001b[39mlemma_ \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m col2 \u001b[39mif\u001b[39;00m token\u001b[39m.\u001b[39mpos_ \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mVERB\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniforge3/envs/commonsense-env/lib/python3.8/site-packages/spacy/language.py:1020\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[1;32m   1019\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1020\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcomponent_cfg\u001b[39m.\u001b[39;49mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1022\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/commonsense-env/lib/python3.8/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/commonsense-env/lib/python3.8/site-packages/spacy/pipeline/transition_parser.pyx:253\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/commonsense-env/lib/python3.8/site-packages/spacy/pipeline/transition_parser.pyx:272\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/commonsense-env/lib/python3.8/site-packages/thinc/model.py:854\u001b[0m, in \u001b[0;36mset_dropout_rate\u001b[0;34m(model, drop, attrs)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[39m\"\"\"Walk over the model's nodes, setting the dropout rate. You can specify\u001b[39;00m\n\u001b[1;32m    851\u001b[0m \u001b[39mone or more attribute names, by default it looks for [\"dropout_rate\"].\u001b[39;00m\n\u001b[1;32m    852\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    853\u001b[0m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mwalk():\n\u001b[0;32m--> 854\u001b[0m     \u001b[39mfor\u001b[39;00m attr \u001b[39min\u001b[39;00m attrs:\n\u001b[1;32m    855\u001b[0m         \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39mattrs:\n\u001b[1;32m    856\u001b[0m             node\u001b[39m.\u001b[39mattrs[attr] \u001b[39m=\u001b[39m drop\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "atomic_train['verbs_head'] = None\n",
    "atomic_train['verbs_tail'] = None\n",
    "for row in tqdm(atomic_train.itertuples(), total=atomic_train_length):\n",
    "    if (not isinstance(row.head, str)) or (not isinstance(row.tail, str)):\n",
    "        continue\n",
    "\n",
    "    col1 = nlp(row.head)\n",
    "    col2 = nlp(row.tail)\n",
    "\n",
    "    tmp1 = set([token.lemma_ for token in col1 if token.pos_ == 'VERB'])\n",
    "    tmp2 = set([token.lemma_ for token in col2 if token.pos_ == 'VERB'])\n",
    "\n",
    "    atomic_train.at[row.Index, 'verbs_head'] = tmp1\n",
    "    atomic_train.at[row.Index, 'verbs_tail'] = tmp2\n",
    "\n",
    "display(atomic_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102024/102024 [00:00<00:00, 1803848.11it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "atomic_dev['verbs_head'] = None\n",
    "atomic_dev['verbs_tail'] = None\n",
    "for row in tqdm(atomic_dev.itertuples(), total=atomic_dev_length):\n",
    "    if (not isinstance(row.head, str)) or (not isinstance(row.tail, str)):\n",
    "        continue\n",
    "    \n",
    "    col1 = nlp(row.head)\n",
    "    col2 = nlp(row.tail)\n",
    "\n",
    "    tmp1 = set([token.lemma_ for token in col1 if token.pos_ == 'VERB'])\n",
    "    tmp2 = set([token.lemma_ for token in col2 if token.pos_ == 'VERB'])\n",
    "\n",
    "    atomic_dev.at[row.Index, 'verbs_head'] = tmp1\n",
    "    atomic_dev.at[row.Index, 'verbs_tail'] = tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152209/152209 [00:00<00:00, 1810914.71it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "atomic_test['verbs_head'] = None\n",
    "atomic_test['verbs_tail'] = None\n",
    "for row in tqdm(atomic_test.itertuples(), total=atomic_test_length):\n",
    "    if (not isinstance(row.head, str)) or (not isinstance(row.tail, str)):\n",
    "        continue\n",
    "    \n",
    "    col1 = nlp(row.head)\n",
    "    col2 = nlp(row.tail)\n",
    "\n",
    "    tmp1 = set([token.lemma_ for token in col1 if token.pos_ == 'VERB'])\n",
    "    tmp2 = set([token.lemma_ for token in col2 if token.pos_ == 'VERB'])\n",
    "\n",
    "    atomic_test.at[row.Index, 'verbs_head'] = tmp1\n",
    "    atomic_test.at[row.Index, 'verbs_tail'] = tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1076880 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for &: 'NoneType' and 'set'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/woojinkim/Codes/commonsense-reasoning/atomic-extract.ipynb Cell 39\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/woojinkim/Codes/commonsense-reasoning/atomic-extract.ipynb#X65sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m atomic_train[\u001b[39m'\u001b[39m\u001b[39mmatch\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/woojinkim/Codes/commonsense-reasoning/atomic-extract.ipynb#X65sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m tqdm(atomic_train\u001b[39m.\u001b[39mitertuples(), total\u001b[39m=\u001b[39matomic_train_length):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/woojinkim/Codes/commonsense-reasoning/atomic-extract.ipynb#X65sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mif\u001b[39;00m (row\u001b[39m.\u001b[39;49mverbs_head \u001b[39m&\u001b[39;49m piqa_verbs) \u001b[39mor\u001b[39;00m (row\u001b[39m.\u001b[39mverbs_tail \u001b[39m&\u001b[39m piqa_verbs):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/woojinkim/Codes/commonsense-reasoning/atomic-extract.ipynb#X65sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         atomic_train\u001b[39m.\u001b[39mat[row\u001b[39m.\u001b[39mIndex, \u001b[39m'\u001b[39m\u001b[39mmatch\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/woojinkim/Codes/commonsense-reasoning/atomic-extract.ipynb#X65sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m display(atomic_train[atomic_train[\u001b[39m'\u001b[39m\u001b[39mmatch\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m]\u001b[39m.\u001b[39mhead())\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for &: 'NoneType' and 'set'"
     ]
    }
   ],
   "source": [
    "atomic_train['match'] = None\n",
    "for row in tqdm(atomic_train.itertuples(), total=atomic_train_length):\n",
    "    if not isinstance(piqa_verbs, set):\n",
    "        continue\n",
    "\n",
    "    if (row.verbs_head & piqa_verbs) or (row.verbs_tail & piqa_verbs):\n",
    "        atomic_train.at[row.Index, 'match'] = True\n",
    "        \n",
    "display(atomic_train[atomic_train['match'] == True].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_dev['match'] = None\n",
    "for row in tqdm(atomic_dev.itertuples(), total=atomic_length):\n",
    "    if not isinstance(piqa_verbs, set):\n",
    "        continue\n",
    "    \n",
    "    if (row.verbs_head & piqa_verbs) or (row.verbs_tail & piqa_verbs):\n",
    "        atomic_dev.at[row.Index, 'match'] = True\n",
    "\n",
    "display(atomic_dev[atomic_dev['match'] == True].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_test['match'] = None\n",
    "for row in tqdm(atomic_test.itertuples(), total=atomic_length):\n",
    "    if not isinstance(piqa_verbs, set):\n",
    "        continue\n",
    "    \n",
    "    if (row.verbs_head & piqa_verbs) or (row.verbs_tail & piqa_verbs):\n",
    "        atomic_test.at[row.Index, 'match'] = True\n",
    "\n",
    "display(atomic_test[atomic_test['match'] == True].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_train[atomic_train['match'] == True][['head', 'relation', 'tail']].to_csv(\n",
    "    \"./output/atomic_train_match.tsv\", sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_dev[atomic_dev['match'] == True][['head', 'relation', 'tail']].to_csv(\n",
    "    \"./output/atomic_dev_match.tsv\", sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_test[atomic_test['match'] == True][['head', 'relation', 'tail']].to_csv(\n",
    "    \"./output/atomic_test_match.tsv\", sep='\\t', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('commonsense-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f4007100c6443a8e727b9f63f13e080e1241b0bd453ef16fb4b6d271ac8f8bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
